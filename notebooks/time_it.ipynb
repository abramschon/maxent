{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06a00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, njit, prange, void, int8, float32\n",
    "import scipy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e347bf8",
   "metadata": {},
   "source": [
    "## Timing setting up the state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc75001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(n, width, dtype=np.int8):\n",
    "    \"\"\"\n",
    "    Returns a binary rep of the int n as an array of size width, e.g. Assuming N = 5, 3 -> np.array([0,0,0,1,1]) \n",
    "    Not particularly efficient, but since it is only used once at the start for small N, this is okay\n",
    "    \"\"\"\n",
    "    b = np.zeros(width,dtype=dtype)\n",
    "    for i in range(width):\n",
    "        if n % 2 == 1: \n",
    "            b[width-1-i]=1 # index N-1-i otherwise numbers are reversed\n",
    "        else:\n",
    "            b[width-1-i]=0\n",
    "        n//=2\n",
    "        if n==0: break\n",
    "    return b\n",
    "\n",
    "def get_state_space(width, dtype=np.int8):\n",
    "    \"\"\"\n",
    "    Sets up the state space, but only if analytic expectations are needed\n",
    "    \"\"\"\n",
    "    return np.array([to_binary(n, width, dtype) for n in range(2**width)],dtype=dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d8cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def n_to_binary(n, width):\n",
    "    \"\"\"\n",
    "    Returns a binary rep of the int n as an array of size width, e.g. Assuming N = 5, 3 -> np.array([0,0,0,1,1]) \n",
    "    Not particularly efficient, but since it is only used once at the start for small N, this is okay\n",
    "    \"\"\"\n",
    "    b = np.zeros(width)\n",
    "    for i in range(width):\n",
    "        if n % 2 == 1: \n",
    "            b[width-1-i]=1 # index N-1-i otherwise numbers are reversed\n",
    "        else:\n",
    "            b[width-1-i]=0\n",
    "        n//=2\n",
    "        if n==0: break\n",
    "    return b\n",
    "\n",
    "@njit\n",
    "def n_get_state_space(width):\n",
    "    \"\"\"\n",
    "    Sets up the state space, but only if analytic expectations are needed\n",
    "    \"\"\"\n",
    "    space = np.zeros((2**width,width))\n",
    "    for n in range(2**width):\n",
    "        space[n] = n_to_binary(n, width)\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d64aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2 s ± 438 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "417 ms ± 11.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_state_space(10)\n",
    "%timeit n_get_state_space(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371b844",
   "metadata": {},
   "source": [
    "# Timing generating Gibbs samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bcbae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def gibbs_sampling(p           : \"numba function which returns unnormalized probability of state s\",\n",
    "                   init_states : \"CxN matrix of initial states for each Markov chain \",\n",
    "                   M           : \"number of samples per chain\",\n",
    "                   avg_every   : \"how many transitions before we take the next sample\",\n",
    "                   burn_in     : \"how many samples we initially discard\"):\n",
    "    \"\"\"\n",
    "    Returns M x C samples based on the given unnormalised probability mass function p\n",
    "    Assumes 0,1 notation\n",
    "    \"\"\"\n",
    "    C, N = init_states.shape\n",
    "    its = M*avg_every+burn_in # number of iterations per chain\n",
    "    samples = np.zeros((C,its,N)) #initialise samples\n",
    "    for c in range(C):\n",
    "        samples[c,0,:] = init_states[c] #set the initial state \n",
    "        \n",
    "    # do gibbs sampling\n",
    "    for c in range(C):\n",
    "        for t in range(1,its): \n",
    "            samples[c,t] = samples[c,t-1] #copy previous state\n",
    "            i = t % N #which dimension to work on\n",
    "\n",
    "            state_off = np.copy(samples[c,t])\n",
    "            state_on = np.copy(samples[c,t])\n",
    "            \n",
    "            state_off[i] =  0 #state with neuron i set to off\n",
    "            state_on[i] = 1 #state with neuron i set to on\n",
    "            \n",
    "            p_off = p(state_off)\n",
    "            denom = (p_off + p(state_on) )\n",
    "            if denom == 0: # implies p_off and p_on is zero, so some numerical error\n",
    "                p_cond_off = np.random.rand(1)[0]\n",
    "            else:\n",
    "                p_cond_off = p_off / denom #calc cond prob that spin i is on given other spin vals\n",
    "            \n",
    "            if np.random.binomial(1,p_cond_off): #draw number from unif distribution to determine whether we update i\n",
    "                samples[c,t]=state_off\n",
    "                continue\n",
    "            samples[c,t]=state_on\n",
    "            \n",
    "    samples = np.copy(samples[:,burn_in::avg_every]) # discard burn in and take every `avg_every` sample\n",
    "    \n",
    "    return samples.reshape((C*M,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1049df3b",
   "metadata": {},
   "source": [
    "## Helper functions for MC gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c9c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_ind_samples(avgs,C):\n",
    "    N = avgs.shape[0]\n",
    "    states = np.zeros((C,N))\n",
    "    for c in range(C):\n",
    "        for n in range(N):\n",
    "            states[c,n] = np.random.binomial(1,avgs[n]) \n",
    "    return states\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f1327db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def p(s, h, J):\n",
    "    \"\"\"\n",
    "    Returns the unnormalized probability (not divided by Z) of the state/states s \n",
    "    \"\"\"\n",
    "    if s.ndim==1:\n",
    "        return np.exp( - s.dot(h) - s.dot(J).dot(s) )\n",
    "    return np.exp(-s.dot(h) - np.sum(s.dot(J)*s, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f602cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def sample_corrs(X,Y):\n",
    "    \"\"\"\n",
    "    A convenience method used above\n",
    "    X is an M x N matrix of states\n",
    "    Y is an M vector of values for each state\n",
    "    \"\"\"\n",
    "    N = X.shape[1]\n",
    "    corrs = np.zeros((N,N))\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1,N):\n",
    "            corrs[i,j] = np.sum( Y[ X[:,i]*X[:,j] == 1 ] )\n",
    "    return corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b239ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def update_weights(i, p, samples, h, J, h_old, J_old, lr):\n",
    "    n_samples = samples.shape[0]\n",
    "    if i == 0:\n",
    "        Ps = np.ones(n_samples) \n",
    "    else:\n",
    "        Ps = p(samples, h-h_old, J-J_old) # like the likelihood of each state, but based on samples \n",
    "\n",
    "    denom = n_samples * np.mean(Ps) \n",
    "    if denom == 0:\n",
    "        print(\"Divide by zero issue\", Ps)\n",
    "        denom = 1e-4 \n",
    "\n",
    "    mod_avgs = samples.T.dot(Ps) / denom\n",
    "    mod_corrs = sample_corrs(samples,Ps) / denom\n",
    "\n",
    "    #update h and J\n",
    "    h = h + lr*(mod_avgs - avgs)\n",
    "    J = J + lr*(mod_corrs - corrs)\n",
    "    return h, J, mod_avgs, mod_corrs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e97629ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_gradient_ascent(p               :\"function that returns unnorm. prob of states\",\n",
    "                        h               :\"vector of weights associated with local fields\",\n",
    "                        J               :\"matrix of weights associated with interactions\",\n",
    "                        avgs            :\"avgs we wish to reproduce\",\n",
    "                        corrs           :\"correlations we wish to reproduce\",\n",
    "                        M               :\"number of gibbs samples we create\",  \n",
    "                        C               :\"number of chains\", \n",
    "                        N_sets          :\"number of times we generate gibbs samples\", \n",
    "                        updates_per_set :\"number of updates per gibbs sample\", \n",
    "                        avg_every       :\"how many samples we skip\",\n",
    "                        burn_in         :\"how many samples we discard\", \n",
    "                        lr              :\"learning rate\",\n",
    "                        seed            :\"seed for random components\"\n",
    "                       ):\n",
    "        \"\"\"\n",
    "        Performs gradient ascent, but uses gibbs sampling to work out expectations and reuses samples for multiple updates\n",
    "        \"\"\"\n",
    "        np.random.seed(seed) # set seed\n",
    "        \n",
    "        N = h.shape[0] #get no neurons\n",
    "        \n",
    "        # get inital states using an independent approximation\n",
    "        init_states = get_ind_samples(avgs,C)\n",
    "        \n",
    "        h_old = h\n",
    "        J_old = J\n",
    "        \n",
    "        save_avs = np.zeros((N_sets, N))\n",
    "        save_corrs = np.zeros((N_sets, N,N))\n",
    "        \n",
    "        for u in range(N_sets):\n",
    "            @njit\n",
    "            def p_fix(s):\n",
    "                return p(s,h,J)\n",
    "            print(\"Sampling...\")\n",
    "            samples = gibbs_sampling(p_fix, init_states, M, avg_every, burn_in) #generate set of samples with current h and J\n",
    "            \n",
    "            for i in tqdm(range(updates_per_set)): #gradient ascent based on the samples\n",
    "                h, J, mod_avgs, mod_corrs = update_weights(i, p, samples, h, J, h_old, J_old, lr)\n",
    "            \n",
    "            #update h and J that generate samples\n",
    "            h_old = h\n",
    "            J_old = J\n",
    "            init_states = samples[-C:] #take the last C samples as the initial states for next sampling\n",
    "            \n",
    "            # save model averages\n",
    "            save_avs[u] = mod_avgs\n",
    "            save_corrs[u] = mod_corrs\n",
    "        \n",
    "        return h, J, save_avs, save_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fedf22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def pert_init(avgs,corrs):\n",
    "    \"\"\"\n",
    "    Initialise weights based on estimates from the perturbative results\n",
    "    Div by 0 issue if any average is 0\n",
    "    \"\"\"\n",
    "    N = avgs.shape[0]\n",
    "    h = np.log( (1/avgs) - 1)\n",
    "    prod_avgs = np.outer(avgs,avgs)\n",
    "    J = -np.log( (corrs / prod_avgs) + np.tril( np.ones((N,N)))  ) \n",
    "    return h,J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef691df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "avgs = np.ones(N)*0.5\n",
    "corrs = np.ones((N,N))*0.02\n",
    "h, J = pert_init(avgs,corrs)\n",
    "M = 1000\n",
    "C = 2\n",
    "N_sets = 5\n",
    "updates_per_set = 50\n",
    "avg_every = N\n",
    "burn_in = N\n",
    "lr=0.1\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1684681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 354.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 429.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 432.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 446.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 397.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 421.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 437.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 476.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 462.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 456.59it/s]\n"
     ]
    }
   ],
   "source": [
    "h, J, save_avs, save_corrs = num_gradient_ascent(p, h, J, avgs, corrs, M, C, 10, updates_per_set, avg_every, burn_in, 0.1, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffe4bb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66887833, 0.56276053, 0.        , 0.40323453, 0.        ,\n",
       "        0.        , 0.        , 0.33299063, 0.33436982, 0.33563848,\n",
       "        0.        , 0.31362782, 0.        , 0.28313765, 0.66436152,\n",
       "        1.        , 1.        , 0.        , 0.43723947, 0.        ],\n",
       "       [0.        , 0.6853146 , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.14527321, 0.34626396, 1.        , 1.        ,\n",
       "        0.65904622, 0.        , 0.        , 0.14723715, 0.        ,\n",
       "        0.33955248, 0.66044752, 0.        , 0.65564363, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.64011338, 0.35200828, 0.76820389, 0.5685315 ,\n",
       "        0.67114295, 0.        , 0.        , 0.        , 0.40831727,\n",
       "        0.        , 0.59168273, 0.        , 1.        , 0.        ],\n",
       "       [0.49833497, 0.29245143, 0.        , 0.32011875, 0.        ,\n",
       "        0.44602279, 0.26244636, 0.56042509, 0.4240205 , 0.84620204,\n",
       "        0.        , 0.16978621, 0.        , 0.14993353, 0.42749358,\n",
       "        0.56767823, 0.        , 0.21246864, 0.43232177, 0.40692765],\n",
       "       [0.34098804, 0.56248398, 0.        , 0.        , 0.        ,\n",
       "        0.49760333, 0.        , 0.58859739, 0.30533751, 0.32668148,\n",
       "        0.40985134, 0.        , 0.        , 0.3557279 , 0.40517767,\n",
       "        0.80970921, 0.60175482, 0.66012901, 0.        , 0.13597587],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.62623453, 0.        , 0.        , 0.38615992, 0.50086975,\n",
       "        0.4867358 , 1.        , 0.51190101, 0.48809899, 0.        ],\n",
       "       [0.31028243, 0.33788649, 0.34312993, 0.4742818 , 0.5119603 ,\n",
       "        0.12898444, 0.21786702, 0.13697455, 0.33579731, 0.49324559,\n",
       "        0.        , 0.33402591, 0.54957484, 0.4903455 , 0.        ,\n",
       "        0.        , 0.29735405, 0.        , 0.47286107, 0.56618251],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.59923178, 0.        , 0.        , 0.58631205, 0.        ,\n",
       "        0.        , 0.59629871, 1.        , 0.3607662 , 0.40076935,\n",
       "        0.45662666, 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.40612997, 0.        , 0.2622425 , 0.33162753, 0.        ],\n",
       "       [0.76311093, 0.        , 0.        , 0.59155419, 0.24824079,\n",
       "        0.        , 0.        , 0.27647034, 0.59669086, 0.        ,\n",
       "        0.62399005, 0.40390182, 0.61289904, 0.40785519, 0.47528885,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_avs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d17839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
